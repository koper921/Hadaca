{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, mean_squared_error, log_loss\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : (685, 20103)\n",
      "Shape of y : (685,)\n",
      "labels : Index(['stage ib', 'stage ia', 'stage i', 'stage iib', 'stage iv',\n",
      "       'stage iiia', 'not reported', 'stage iia', 'stage ii', 'stage iiib'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données\n",
    "df_data = pd.read_csv(\"clean_data.csv\")\n",
    "df_metadata = pd.read_csv(\"metadata.csv\")\n",
    "# df_data_t = df_data.transpose()\n",
    "# df_metadata\n",
    "\n",
    "# Convertir les données en ndarray et supprimer les colonnes inutiles\n",
    "X = df_data.loc[:, ~df_data.columns.str.contains('^Unnamed')].values\n",
    "X = X.T\n",
    "\n",
    "# Générer les labels en fonction d'une colonne choisie\n",
    "s = pd.Series(df_metadata[\"tumor_stage\"].values)\n",
    "labels,values = pd.factorize(s)\n",
    "y = labels\n",
    "\n",
    "print(\"Shape of X :\", X.shape)\n",
    "print(\"Shape of y :\", y.shape)\n",
    "\n",
    "print(\"labels :\", values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(685, 1000)\n"
     ]
    }
   ],
   "source": [
    "# selection des k best features grâce au test chi2\n",
    "\n",
    "chi2_selector = SelectKBest(chi2, k=1000)\n",
    "X = chi2_selector.fit_transform(X, y)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # stratify=y, mais une classe avec 1 occurences,on vire cette classe? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(548, 100)\n",
      "(100, 1000)\n",
      "(548, 1000)\n",
      "RMSE = 0.0014479786530833807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components = 100)\n",
    "A = svd.fit_transform(X_train)\n",
    "T = svd.components_\n",
    "print(A.shape)\n",
    "print(T.shape)\n",
    "D = np.dot(A,T)\n",
    "print(D.shape)\n",
    "################ WARNING ###############\n",
    "# pearson = np.corrcoef(D,X_art)\n",
    "# print(\"Pearson =\", pearson) \n",
    "########################################\n",
    "\n",
    "rmse = mean_squared_error(D,X_train)\n",
    "print(\"RMSE =\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00        49\n",
      "           0       0.46      0.79      0.58       141\n",
      "           1       0.51      0.82      0.63       131\n",
      "           2       1.00      0.40      0.57         5\n",
      "           3       0.92      0.19      0.32        63\n",
      "           4       1.00      0.23      0.38        26\n",
      "           5       0.87      0.19      0.31        68\n",
      "           6       1.00      0.11      0.20         9\n",
      "           7       1.00      0.14      0.25        42\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       1.00      0.31      0.47        13\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       548\n",
      "   macro avg       0.80      0.38      0.43       548\n",
      "weighted avg       0.72      0.57      0.52       548\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.75      0.56        12\n",
      "           0       0.24      0.60      0.34        30\n",
      "           1       0.25      0.33      0.29        27\n",
      "           3       0.00      0.00      0.00        28\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00        21\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00        11\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.26      0.26      0.26       137\n",
      "   macro avg       0.10      0.19      0.13       137\n",
      "weighted avg       0.14      0.26      0.18       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(C=10.)\n",
    "model.fit(A,y_train)\n",
    "pred_train = model.predict(A)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_train,pred_train))\n",
    "A_test = svd.fit_transform(X_test)\n",
    "pred_test = model.predict(A_test)\n",
    "\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genérer des données méthode 1 : moyenne, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_artificial_data(data, lbls, nb_of_new, noise = True):\n",
    "    \n",
    "    sigma_noise = 10e-2\n",
    "    new_X = np.zeros((data.shape[1],0))\n",
    "    new_y = np.zeros((0))\n",
    "\n",
    "    for label in np.unique(y):\n",
    "\n",
    "        X_cond = data[np.where(lbls==label)] # X correspondant à un label    \n",
    "        # estimation des paramètres de la normale\n",
    "        mean_X = np.mean(X_cond, axis=0)\n",
    "        std_X = np.std(X_cond, axis=0) \n",
    "\n",
    "        # nombre de nouveaux patiends à ajouter\n",
    "\n",
    "        nb_new_patients_cond = int(nb_of_new*(len(lbls[np.where(lbls==label)])/lbls.shape[0]))\n",
    "        \n",
    "\n",
    "        # generer les labels\n",
    "        \n",
    "        y_cond = np.empty(nb_new_patients_cond)\n",
    "        y_cond.fill(label)\n",
    "\n",
    "        \n",
    "        # boucle qui genere des nombres aléatoires suivant\n",
    "        # une loi normale avec les paramètres calculés\n",
    "\n",
    "        new_X_cond = np.zeros((0,nb_new_patients_cond))\n",
    "\n",
    "        for i in range(X.shape[1]):\n",
    "            new_feature = np.random.normal(mean_X[i], std_X[i], (1,nb_new_patients_cond))\n",
    "            if(noise):\n",
    "                new_feature += np.random.normal(0,1, new_feature.shape)*sigma_noise\n",
    "            new_X_cond = np.append(new_X_cond,new_feature, axis=0)\n",
    "\n",
    "        new_X = np.concatenate((new_X,new_X_cond),axis=1)\n",
    "        new_y = np.append(new_y, y_cond)\n",
    "\n",
    "    new_X = MinMaxScaler().fit_transform(new_X.T)\n",
    "    \n",
    "    \n",
    "    print(new_X.shape)\n",
    "    print(new_y.shape)\n",
    "    \n",
    "    return (new_X,new_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14995, 1000)\n",
      "(14995,)\n"
     ]
    }
   ],
   "source": [
    "X_art,y_art = generate_artificial_data(X_train,y_train,15001)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_art, y_art, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14995, 100)\n",
      "(100, 1000)\n",
      "(14995, 1000)\n",
      "RMSE = 0.10442430121866922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components = 100)\n",
    "A = svd.fit_transform(X_art)\n",
    "A_test = svd.fit_transform(X_test)\n",
    "\n",
    "T = svd.components_\n",
    "print(A.shape)\n",
    "print(T.shape)\n",
    "D = np.dot(A,T)\n",
    "print(D.shape)\n",
    "################ WARNING ###############\n",
    "# pearson = np.corrcoef(D,X_art)\n",
    "# print(\"Pearson =\", pearson) \n",
    "########################################\n",
    "\n",
    "rmse = mean_squared_error(D,X_art)\n",
    "print(\"RMSE =\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      1.00      1.00      1341\n",
      "         0.0       0.77      0.84      0.81      3859\n",
      "         1.0       0.88      0.91      0.90      3586\n",
      "         2.0       1.00      1.00      1.00       136\n",
      "         3.0       0.79      0.79      0.79      1724\n",
      "         4.0       0.91      0.83      0.87       711\n",
      "         5.0       0.71      0.56      0.62      1861\n",
      "         6.0       1.00      1.00      1.00       246\n",
      "         7.0       0.98      0.97      0.97      1149\n",
      "         8.0       1.00      1.00      1.00        27\n",
      "         9.0       0.98      0.90      0.94       355\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     14995\n",
      "   macro avg       0.91      0.89      0.90     14995\n",
      "weighted avg       0.85      0.85      0.85     14995\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.13      1.00      0.22        12\n",
      "         0.0       0.00      0.00      0.00        30\n",
      "         1.0       0.00      0.00      0.00        27\n",
      "         3.0       0.00      0.00      0.00        28\n",
      "         4.0       0.00      0.00      0.00         5\n",
      "         5.0       0.00      0.00      0.00        21\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "         7.0       0.00      0.00      0.00        11\n",
      "         8.0       0.00      0.00      0.00         0\n",
      "         9.0       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.09      0.09      0.09       137\n",
      "   macro avg       0.01      0.10      0.02       137\n",
      "weighted avg       0.01      0.09      0.02       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(C=10.)\n",
    "model.fit(A_train,y_art)\n",
    "pred_train = model.predict(A_train)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_art,pred_train))\n",
    "pred_test = model.predict(A_test)\n",
    "\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genérer des données méthode 2 : SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 141, 1: 131, 5: 68, 3: 63, -1: 49, 7: 42, 4: 26, 9: 13, 6: 9, 2: 5, 8: 1})\n",
      "(547, 1000)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "# 6 occurences nécessaire pour Smote ou Adasyn, on enlève la classe 8 et on duplique occurence de 2  la classe 5 \n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "\n",
    "recounted = Counter(y_train)\n",
    "print(recounted)\n",
    "\n",
    "X_train_sans_8= X_train[np.where(y_train!=8)  ]\n",
    "X_2 = X_train[np.where(y_train==2)  ][0]\n",
    "print(X_train_sans_8.shape)\n",
    "print(X_2.shape)\n",
    "X_train_sans_8_1 = np.vstack( [X_train_sans_8,X_2  ])\n",
    "X_train_sans_8_1.shape\n",
    "\n",
    "\n",
    "\n",
    "y_train_sans_8= y_train[np.where(y_train!=8)  ]\n",
    "\n",
    "y_train_sans_8 = np.append(y_train_sans_8, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 5 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 3 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class -1 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 7 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 4 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 9 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 6 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 2 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(548, 1000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# nombre d'occurences désirées par classe \n",
    "# # on a enlevé la classe 8 car qu'une occurence impossible d'appliquer SMOTE ou ADASYN\n",
    "dict= {0: 1000, 1: 1000, 5: 1000, 3: 1000, -1: 1000, 7: 1000, 4: 1000, 9: 1000, 6: 1000, 2: 1000}  \n",
    "smote = SMOTE(random_state=42, sampling_strategy=dict)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_sans_8_1, y_train_sans_8)\n",
    "print(X_resampled.shape)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n",
      "(100, 1000)\n",
      "(10000, 1000)\n",
      "RMSE = 0.01251947645624487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components = 100)\n",
    "A = svd.fit_transform(X_resampled)\n",
    "A_test = svd.fit_transform(X_test)\n",
    "\n",
    "T = svd.components_\n",
    "print(A.shape)\n",
    "print(T.shape)\n",
    "D = np.dot(A,T)\n",
    "print(D.shape)\n",
    "################ WARNING ###############\n",
    "# pearson = np.corrcoef(D,X_art)\n",
    "# print(\"Pearson =\", pearson) \n",
    "########################################\n",
    "\n",
    "rmse = mean_squared_error(D,X_resampled)\n",
    "print(\"RMSE =\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      1000\n",
      "           0       0.88      0.81      0.84      1000\n",
      "           1       0.78      0.83      0.81      1000\n",
      "           2       1.00      1.00      1.00      1000\n",
      "           3       0.92      0.91      0.92      1000\n",
      "           4       0.98      1.00      0.99      1000\n",
      "           5       0.92      0.91      0.91      1000\n",
      "           6       1.00      1.00      1.00      1000\n",
      "           7       0.97      0.98      0.98      1000\n",
      "           9       1.00      1.00      1.00      1000\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     10000\n",
      "   macro avg       0.94      0.94      0.94     10000\n",
      "weighted avg       0.94      0.94      0.94     10000\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.92      0.67        12\n",
      "           0       0.29      0.30      0.30        30\n",
      "           1       0.21      0.22      0.21        27\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.55      0.21      0.31        28\n",
      "           4       0.14      0.20      0.17         5\n",
      "           5       0.31      0.19      0.24        21\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00        11\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.27      0.27      0.27       137\n",
      "   macro avg       0.20      0.20      0.19       137\n",
      "weighted avg       0.31      0.27      0.27       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(C=10.)\n",
    "model.fit(A,y_resampled)\n",
    "pred_train = model.predict(A)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "pred_test = model.predict(A_test)\n",
    "\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      1000\n",
      "           0       1.00      1.00      1.00      1000\n",
      "           1       1.00      1.00      1.00      1000\n",
      "           2       1.00      1.00      1.00      1000\n",
      "           3       1.00      1.00      1.00      1000\n",
      "           4       1.00      1.00      1.00      1000\n",
      "           5       1.00      1.00      1.00      1000\n",
      "           6       1.00      1.00      1.00      1000\n",
      "           7       1.00      1.00      1.00      1000\n",
      "           9       1.00      1.00      1.00      1000\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     10000\n",
      "   macro avg       1.00      1.00      1.00     10000\n",
      "weighted avg       1.00      1.00      1.00     10000\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.92      0.85        12\n",
      "           0       0.28      0.43      0.34        30\n",
      "           1       0.20      0.15      0.17        27\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.25      0.11      0.15        28\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.13      0.10      0.11        21\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.22      0.18      0.20        11\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.26      0.26      0.26       137\n",
      "   macro avg       0.19      0.19      0.18       137\n",
      "weighted avg       0.26      0.26      0.25       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "model1 = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)\n",
    "\n",
    "model1.fit(A,y_resampled)\n",
    "pred_train = model1.predict(A)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled,pred_train))\n",
    "pred_test = model1.predict(A_test)\n",
    "\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Générer des données méthode 3 : ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 5 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 3 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class -1 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 7 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 4 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 9 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 6 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n",
      "D:\\Programmes\\Anaconda2\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (1000) in class 2 will be larger than the number of samples in the majority class (class #0 -> 141)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n",
      "(548, 1000)\n"
     ]
    }
   ],
   "source": [
    "# nombre d'occurences désirées par classe \n",
    "# # on a enlevé la classe 8 car qu'une occurence impossible d'appliquer SMOTE ou ADASYN\n",
    "dict= {0: 1000, 1: 1000, 5: 1000, 3: 1000, -1: 1000, 7: 1000, 4: 1000, 9: 1000, 6: 1000, 2: 1000}  \n",
    "ada = ADASYN(random_state=42, sampling_strategy=dict)\n",
    "X_resampled_ada, y_resampled_ada = ada.fit_resample(X_train_sans_8_1, y_train_sans_8)\n",
    "print(X_resampled.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9991, 100)\n",
      "(100, 1000)\n",
      "(9991, 1000)\n",
      "RMSE = 0.011733816776209374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components = 100)\n",
    "A = svd.fit_transform(X_resampled_ada)\n",
    "A_test = svd.fit_transform(X_test)\n",
    "\n",
    "T = svd.components_\n",
    "print(A.shape)\n",
    "print(T.shape)\n",
    "D = np.dot(A,T)\n",
    "print(D.shape)\n",
    "################ WARNING ###############\n",
    "# pearson = np.corrcoef(D,X_art)\n",
    "# print(\"Pearson =\", pearson) \n",
    "########################################\n",
    "\n",
    "rmse = mean_squared_error(D,X_resampled_ada)\n",
    "print(\"RMSE =\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      1001\n",
      "           0       1.00      1.00      1.00       978\n",
      "           1       1.00      1.00      1.00       997\n",
      "           2       1.00      1.00      1.00      1002\n",
      "           3       1.00      1.00      1.00       987\n",
      "           4       1.00      1.00      1.00       998\n",
      "           5       1.00      1.00      1.00      1014\n",
      "           6       1.00      1.00      1.00      1003\n",
      "           7       1.00      1.00      1.00      1012\n",
      "           9       1.00      1.00      1.00       999\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      9991\n",
      "   macro avg       1.00      1.00      1.00      9991\n",
      "weighted avg       1.00      1.00      1.00      9991\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.92      0.79        12\n",
      "           0       0.13      0.17      0.15        30\n",
      "           1       0.20      0.19      0.19        27\n",
      "           3       0.17      0.11      0.13        28\n",
      "           4       0.08      0.20      0.12         5\n",
      "           5       0.18      0.10      0.12        21\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.23      0.27      0.25        11\n",
      "           9       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.22      0.22      0.22       137\n",
      "   macro avg       0.19      0.22      0.19       137\n",
      "weighted avg       0.21      0.22      0.21       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "model1 = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)\n",
    "\n",
    "model1.fit(A,y_resampled_ada)\n",
    "pred_train = model1.predict(A)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(classification_report(y_resampled_ada,pred_train))\n",
    "pred_test = model1.predict(A_test)\n",
    "\n",
    "print(\"Test:\")\n",
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14994, 1000)\n",
      "(14994,)\n",
      "(4996, 1000)\n",
      "(4996,)\n"
     ]
    }
   ],
   "source": [
    "X_train_art,y_train_art = generate_artificial_data(X,y,15001)\n",
    "X_test_art, y_test_art = generate_artificial_data(X,y,5001)\n",
    "\n",
    "df_train_X = pd.DataFrame(X_train_art)\n",
    "df_train_X.to_csv(\"data/challenge/train/data.csv\")\n",
    "df_train_y = pd.DataFrame(y_train_art)\n",
    "df_train_y.to_csv(\"data/challenge/train/metadata.csv\")\n",
    "\n",
    "df_test_X = pd.DataFrame(X_test_art)\n",
    "df_test_X.to_csv(\"data/challenge/test/data.csv\")\n",
    "df_test_y = pd.DataFrame(y_test_art)\n",
    "df_test_y.to_csv(\"data/challenge/test/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]]\n",
      "[[ 0.00163597  0.0052493   0.00546016 -0.00536443  0.0025316 ]]\n"
     ]
    }
   ],
   "source": [
    "ar1 = np.zeros((1,5))\n",
    "print(ar1)\n",
    "print(ar1 + np.random.normal(0,1, ar1.shape)*1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
